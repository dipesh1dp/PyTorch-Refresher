





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch





# scalars have zero dimension
scalar = torch.tensor(5)
print(scalar)


# one dimensional tensor
vector = torch.tensor([2,3])
random_vec = torch.rand(2)
vector, random_vec, vector.ndim


# three dimensional tensor
matrix = torch.tensor([[2,3,4], [5,6,7]])
random_mat = torch.rand(2,3)
matrix, random_mat


one_to_5 = torch.arange(1, 10).reshape(3,3)
one_to_5


five_zeros = torch.zeros_like(one_to_5)
five_ones = torch.ones_like(one_to_5)
five_zeros, five_ones





# creating a float32 tensor
float_32_tensor = torch.tensor([2.0, 3, 4, 5.0], dtype=torch.float32, device=None, requires_grad=False)
print(float_32_tensor, float_32_tensor.dtype)

#creating a float16 tensor
float_16_tensor = torch.tensor([2.0, 3, 4, 5.0], dtype=torch.float16, device=None, requires_grad=False)
print(float_16_tensor, float_16_tensor.dtype)

# mutliplying diff dtype tensors
float_32_tensor * float_16_tensor 





# Addition
some_tensor = torch.tensor([2,3,4,5,6])
some_tensor2 = torch.tensor([1,1,1,1,1])
print(some_tensor)
print(some_tensor + 3)  # broadcasting 
print(torch.add(some_tensor, 3))
print(torch.add(some_tensor, some_tensor2))




# subraction
print(some_tensor - 1)
print(torch.sub(some_tensor, 1))
print(torch.sub(some_tensor, some_tensor2))
torch.sub


# multiplication 
print(some_tensor * 2) # broadcasting
print(torch.multiply(some_tensor, 2))  # # broadcasting
print(torch.matmul(some_tensor, some_tensor2))  # matmul --> dot product


# multiplication in higher dimensions
some_matrix1 = torch.arange(1,5).reshape(2,2)
some_matrix2 = torch.arange(5,9).reshape(2,2)

print(f'matrix_1: \n{some_matrix1}\nmatrix_2: \n{some_matrix2}')
print(f'Element-wise Product:\n{torch.mul(some_matrix1, some_matrix2)}')
print(f'Dot Product with matmul:\n{torch.matmul(some_matrix1, some_matrix2)}')
print(f'Dot Product with Mat A @ Mat B: \n{some_matrix1 @ some_matrix2}')


# Inplace operation
some_tensor2.add_(some_tensor)





# finding max
torch.max(some_matrix1), some_matrix1.max()


# Finding min
torch.min(some_matrix1), some_matrix1.min()


# for finding mean you need to change the type as it doesn't support long dtype
torch.mean(some_matrix1.type(torch.float32)), torch.mean(some_matrix2.type(torch.float32))



# Finding sum
torch.sum(some_matrix1), some_matrix1.sum()





print(f'{some_matrix1}, \n{some_matrix2}')
print(some_matrix1.argmin(), some_matrix2.argmin())
print(some_matrix1.argmax(), some_matrix2.argmax())





x = torch.arange(1,13)
x, x.shape


x_reshaped = x.reshape(3,4)
x_reshaped, x_reshaped.shape


z = x.view(3,4) # .view doesnot make changes in z but only views z with defined shape
z[:, 0] = 5
z, x # here the changes made in z also applies in x


x_stacked = torch.stack([x, x], dim = 0)
x_stacked


a = torch.rand(256, 256, 3)
a.shape


# herre the dimensions swapped, the parameters represent the swapping order of dimensions
a.permute(2, 0, 1).shape  # here the color channel is swapped at first 





t = torch.arange(1, 10).reshape(1,3,3)
t, t.shape


t[0], t[0][0], t[0][0][1] 


t[:,0,:], t[:,:,1]





# converting ndarray to tensor 
narray1 = np.arange(1,10)
tensor1 = torch.from_numpy(narray)
narray, tensor1


# convert tensor into ndarray 
tensor2 = torch.arange(1,8)
narray2 = tensor2.numpy()
tensor2, narray2






