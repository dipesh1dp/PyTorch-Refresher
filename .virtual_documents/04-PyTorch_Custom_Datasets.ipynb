











import torch 
from torch import nn 


# setup device-agnostic code
device = 'cuda' if torch.cuda.is_available() else 'cpu'
device





import requests
import zipfile
from pathlib import Path

# setup path to the data 
data_path = Path("data/")
image_path = data_path/"pizza_steak_sushi"

# if the folder doesn't exist download it and prepare it
if image_path.is_dir(): 
    print(f"{image_path} directory already exists... skipping download")
else: 
    print(f"{image_path} doesn't exist, creating one...")
    image_path.mkdir(parents=True, exist_ok=True)

# Download pizza, steak and sushi data 
with open(data_path / "pizza_steak_sushi.zip", "wb") as f: 
    request =  requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
    print(f"Downloading pizza_steak_sushi.zip...")
    f.write(request.content)

# Unzip pizza_steak_sushi.zip
with zipfile.ZipFile(data_path / "pizza_steak_sushi.zip", "r") as zip_ref: 
    zip_ref.extractall(image_path)








import os
def walk_through_dir(dir_path): 
    for dirpath, dirnames, filenames in os.walk(dir_path): 
        print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

walk_through_dir(image_path)


# setup training and testing paths
train_dir = image_path / "train"
test_dir = image_path / "test"

train_dir, test_dir





import random
from PIL import Image

# Set seed 
random.seed(42)

# 1. Get all the image paths
image_path_list = list(image_path.glob("*/*/*.jpg"))

# 2. Pick a random image 
random_image_path = random.choice(image_path_list)

# 3. Get the image class name 
random_image_class = random_image_path.parent.stem

# 4. Open the image 
img = Image.open(random_image_path)

# 5. Print Metadata 
print(f"Random Image path: {random_image_path}")
print(f"Image class: {random_image_class}")
print(f"Image height: {img.height}")
print(f"Image width: {img.width}")
img





import numpy as np 
import matplotlib.pyplot as plt 

# Turn image into array 
img_array = np.asarray(img)

# Plot the image 
plt.figure(figsize=(7,5))
plt.imshow(img_array)
plt.title(f"Image class: {random_image_class} | Image shape: {img_array.shape} -> [H, W, C]")
plt.axis(False)





import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms





data_transform = transforms.Compose([
    # Resize the image to 64x64
    transforms.Resize(size=(64, 64)), 
    # Flip images randomly on the horizontal 
    transforms.RandomHorizontalFlip(p=0.5), 
    # Turn the images into a troch tensor 
    transforms.ToTensor()
])


transformed_image = data_transform(img)
transformed_image.shape, transformed_image.dtype





def plot_transformed_images(image_paths: list, transform, n=3, seed=None): 
    """
    Selects random images from the path of images and loads/transforms them
    then plots the original vs transformed images.
    """
    if seed:
        random.seed(seed)
    random_image_paths = random.sample(image_paths, k=n) 
    for image_path in random_image_paths: 
        with Image.open(image_path) as f: 
            # Plot the original image
            fig, ax = plt.subplots(nrows=1, ncols=2) 
            ax[0].imshow(f) 
            ax[0].set_title(f"Original Image\nShape: {f.size}")
            ax[0].axis(False) 

            # Transforme and plot image
            transformed_image = transform(f).permute(1,2,0) # Changing shape for matplotlib [C, H, W] -> [H, W, C] 
            ax[1].imshow(transformed_image)
            ax[1].set_title(f"Transformed Image\nShape: {transformed_image.shape}")
            ax[1].axis("off") 

            fig.suptitle(f"Class: {image_path.parent.stem}", fontsize=16)

plot_transformed_images(image_paths=image_path_list, 
                        transform=data_transform, 
                        n=3,
                        seed=42)





# Use ImageFolder to create the dataset
from torchvision import datasets
train_data = datasets.ImageFolder(root=train_dir,  
                                  transform=data_transform, # a transform for the data 
                                  target_transform=None)    # a transform for the target/label

test_data = datasets.ImageFolder(root=test_dir, 
                                 transform=data_transform)

train_data, test_data


# Get class names as list 
class_names = train_data.classes
class_names


# Get class names as dict 
class_dict = train_data.class_to_idx
class_dict


# Get a single image and label indexing the dataset 
img, label = train_data[0][0], train_data[0][1] 
print(f"Image Tensor: {img}") 
print(f"Image Shape: {img.shape}")
print(f"Image datatype: {img.dtype}")
print(f"Image Label: {label}") 
print(f"Lable datatype: {type(label)}")


# Rearrang the image dimension for matplotlib 
image_permute = img.permute(1, 2, 0) 
print(f"Original shape: {img.shape} -> [C, H, W]")
print(f"Image permute: {image_permute.shape} -> [H, W, C]")

# Plot the image 
plt.imshow(image_permute)
plt.title(class_names[label]) 
plt.axis(False)





# Turn train and test data into dataloaders
BATCH_SIZE = 1
from torch.utils.data import DataLoader
train_dataloader = DataLoader(dataset=train_data, 
                              batch_size=BATCH_SIZE, 
                              num_workers=1, 
                              shuffle=True)

test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, num_workers=1)

train_dataloader, test_dataloader


len(train_dataloader), len(test_dataloader)





import os 
import pathlib
import torch

from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms
from typing import Tuple, Dict, List





# Instance of torchvision.datasets.ImageFolder() 
train_data.classes, train_data.class_to_idx





# Setup the path for target direcotry 
target_dir = train_dir
print(f"Target directory: {target_dir}")

# Get class names from the target directory
print(list(os.scandir(target_dir)))
# os.scandir() returns DirEntry, so to get names we use entry.name
class_names_found = sorted([entry.name for entry in list(os.scandir(target_dir))]) 
print(f"Labels: {class_names_found}")


# Create a function to get class names 
def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]: 
    """ Finds the class folder names in a target directory... """ 
    # 1. Get the class names by scanning the target directory
    classes = sorted(entry.name for entry in os.scandir(target_dir) if entry.is_dir())

    # 2. Raise an error if the class names aren't found 
    if not classes: 
        raise FileNotFoundError(f"Couldn't find any classes in {target_dir}... please check the file structure")

    # 3. Create a dictionary of index labels 
    class_to_idx = {class_name: i for i, class_name in enumerate(classes)}
    return classes, class_to_idx





from torch.utils.data import Dataset

# 1. Subclass torch.utils.data.Dataset
class ImageFolderCustom(Dataset): 
    # 2. Initialize our custom dataset 
    def __init__(self, 
                 targ_dir: str, 
                 transform=None):
        # Get paths of all images
        self.paths = list(pathlib.Path(targ_dir).glob("*/*.jpg"))
        # Setup transform 
        self.transform=transform
        # 3. Create classes, class_to_idx attributs
        self.classes, self.class_to_idx = find_classes(targ_dir)

    # 4. Create a function to load image 
    def load_image(self, index: int) -> Image.Image: 
        "Opens an image via a path and returns it."
        image_path = self.paths[index]
        return Image.open(image_path)

    # 5. Overwrite the __len__ method 
    def __len__(self) -> int: 
        "Returns the total number of samples" 
        return len(self.paths)

    # 6. Overwrite the __getitem__ method 
    def __getitem__(self, index:int) -> Tuple[torch.Tensor, int]:
        "Returns one sample of data (X, y)" 
        img = self.load_image(index) 
        class_name = self.paths[index].parent.name  # expects the path in the format data_dir/class_dir/image.jpg
        class_idx = self.class_to_idx[class_name]

        # Transform if necessary 
        if self.transform: 
            return self.transform(img), class_idx  # return (X, y)
        else: 
            return img, class_idx
    


# Create a transform 
train_transforms = transforms.Compose([
    transforms.Resize(size=(64, 64)), 
    transforms.RandomHorizontalFlip(p=0.5), 
    transforms.ToTensor()
])

test_transforms = transforms.Compose([
    transforms.Resize(size=(64, 64)), 
    transforms.ToTensor()
])


# Test out the ImageFolderCustom 
train_data_custom = ImageFolderCustom(targ_dir=train_dir,
                                      transform=train_transforms)

test_data_custom = ImageFolderCustom(targ_dir=test_dir, 
                                     transform=test_transforms)

train_data_custom, test_data_custom


len(train_data), len(train_data_custom)


len(test_data), len(test_data_custom)


# check for equality between the original ImageFolder Dataset and ImageFolderCustom Dataset 
print(train_data.classes==train_data_custom.classes) 
print(test_data.classes==test_data_custom.classes)






# 1. Create a function to take in a dataset 
def display_random_images(dataset: torch.utils.data.Dataset, 
                          classes: List[str] = None, 
                          n: int = 10, 
                          display_shape: bool = True, 
                          seed: int = None):

    # 2. Adjust display if n>10 
    if n>10: 
        n = 10 
        print(f"For display purpose, n shouldn't be larger than 10, setting n=10")
    if n>5:
        print("Removing shape display as n>5")
        display_shape=False
    # 3. set random seed if seed is set
    if seed: 
        random.seed(seed)
        
    # 4. Get a list of random indexes 
    random_samples_idx = random.sample(range(len(dataset)), k=n)
    
    # 5. Setup matplotlib 
    plt.figure(figsize=(16, 8))
    
    # 6. Loop through random indexes and plot them with matplotlib 
    for i, targ_sample in enumerate(random_samples_idx): 
        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]
    
        # 7. Adjust dimension for plotting from [C, H, W] -> [H, W, C]
        targ_image_adjust = targ_image.permute(1,2,0) 
    
        # Plot the samples
        plt.subplot(1, n, i+1) 
        plt.imshow(targ_image_adjust)
        plt.axis(False) 
        if classes: 
            title = f"Class: {classes[targ_label]}"
        if display_shape: 
            title = title + f"\nShape: {targ_image_adjust.shape}"
        plt.title(title)


# Display random images form the ImageFolder created Dataset 
display_random_images(train_data_custom, 
                      n=5, 
                      classes=class_names, 
                      seed=None)





from torch.utils.data import DataLoader
BATCH_SIZE = 32 
NUM_WORKERS = 0

# Create train dataloader 
train_dataloader_custom = DataLoader(dataset=train_data_custom, 
                                     batch_size=BATCH_SIZE, 
                                     shuffle=True, 
                                     num_workers=NUM_WORKERS)

test_dataloader_custom = DataLoader(dataset=test_data_custom, 
                                    batch_size=BATCH_SIZE, 
                                    num_workers=NUM_WORKERS)



# Get image and label from custom dataloader 
image_custom, label_custom =  next(iter(train_dataloader_custom))
image_custom.shape, label_custom.shape





# Let's look at trivialaugment
from torchvision import transforms

train_transform = transforms.Compose([
    transforms.Resize(size=(64, 64)), 
    transforms.TrivialAugmentWide(num_magnitude_bins=31), 
    transforms.ToTensor()
])

test_transform = transforms.Compose([
    transforms.Resize(size=(64, 64)), 
    transforms.ToTensor()
])



# Get all the image paths 
image_path_list = list(image_path.glob("*/*/*.jpg")) 
image_path_list[:10]


# Plot random transformed images 
plot_transformed_images(image_path_list, 
                        transform=train_transform, 
                        n=3)








# Creating simple transform 
simple_transform = transforms.Compose([
    transforms.Resize(size=(64,64)), 
    transforms.ToTensor()
])



# 1. Load and transform data 
from torchvision import datasets
train_data_simple = datasets.ImageFolder(root=train_dir, 
                                         transform=simple_transform)
test_data_simple = datasets.ImageFolder(root=test_dir, 
                                        transform=simple_transform)
# 2. Turn the datasets into dataloaders 
import os 
from torch.utils.data import DataLoader

# Setup batch size and num_workers 
BATCH_SIZE = 32
NUM_WORKERS = 0 

# create dataloaders 
train_dataloader_simple = DataLoader(dataset=train_data_simple, 
                                     batch_size=BATCH_SIZE, 
                                     shuffle=True, 
                                     num_workers=NUM_WORKERS) 
test_dataloader_simple = DataLoader(dataset=test_data_custom, 
                                    batch_size=BATCH_SIZE,
                                    shuffle=False,
                                    num_workers=NUM_WORKERS) 






class TinyVGG(nn.Module):
    """
    Model architecture copying TinyVGG from: 
    https://poloclub.github.io/cnn-explainer/
    """
    def __init__(self, 
                 input_shape: int, 
                 hidden_units: int, 
                 output_shape:int) -> None:
        super().__init__() 
        self.conv_block_1 = nn.Sequential(
            nn.Conv2d(in_channels=input_shape, 
                      out_channels=hidden_units, 
                      kernel_size=3, 
                      stride=1, 
                      padding=1), 
            nn.ReLU(), 
            nn.Conv2d(in_channels=hidden_units, 
                      out_channels=hidden_units, 
                      kernel_size=3, 
                      stride=1, 
                      padding=1), 
            nn.ReLU(), 
            nn.MaxPool2d(kernel_size=2, 
                         stride=2)  # defaulat stride value is same as kernel_size
        )
        self.conv_block_2 = nn.Sequential(
            nn.Conv2d(in_channels=hidden_units, 
                      out_channels=hidden_units, 
                      kernel_size=3, 
                      stride=1, 
                      padding=1), 
            nn.ReLU(), 
            nn.Conv2d(in_channels=hidden_units, 
                      out_channels=hidden_units, 
                      kernel_size=3, 
                      stride=1, 
                      padding=1), 
            nn.ReLU(), 
            nn.MaxPool2d(kernel_size=2, 
                         stride=2)  # defaulat stride value is same as kernel_size
        )
        self.classifier = nn.Sequential(
            nn.Flatten(), 
            nn.Linear(in_features=hidden_units*16*16, 
                      out_features=output_shape)
        )

    def forward(self, x): 
        x = self.conv_block_1(x)
        x = self.conv_block_2(x) 
        x = self.classifier(x)
        return x
        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # benefits from operator fusion 
        
        





torch.manual_seed(42) 
model_0 = TinyVGG(input_shape=3, 
                  hidden_units=10, 
                  output_shape=len(class_names)).to(device) 
model_0





image_batch, label_batch = next(iter(train_dataloader_simple)) 

image_batch.shape


# try a forward pass 
model_0(image_batch.to(device))





try: 
    import torchinfo 
except: 
    get_ipython().getoutput("pip install torchinfo")


from torchinfo import summary 
summary(model_0, input_size=[1, 3, 64, 64])





# Create train step function 
def train_step(model: torch.nn.Module, 
               dataloader: torch.utils.data.DataLoader, 
               loss_fn: torch.nn.Module, 
               optimizer: torch.optim.Optimizer, 
               device: torch.device = device): 
    # Put the model on train mode 
    model.train() 

    # Setup loss and accuracy 
    train_loss, train_acc = 0, 0 

    # Loop through data 
    for batch, (X, y) in enumerate(dataloader): 
        # Send data to target device 
        X, y = X.to(device), y.to(device) 

        # 1. Forward Pass 
        y_pred = model(X)  # outputs logits 
        
        # 2. Accumulate loss  
        loss = loss_fn(y_pred, y) 
        train_loss += loss 
        
        # 3. Optimizer zero grad 
        optimizer.zero_grad() 

        # 4. Loss backward 
        loss.backward() 

        # 5. Optimizer step (gradient descent) 
        optimizer.step() 

        # 6. Calculate accuracy metric 
        y_pred_classes = torch.argmax(torch.softmax(y_pred, dim=1), dim=1) # logits -> probs -> classes
        train_acc += (y_pred_classes == y).sum().item()/len(y_pred) 

    # Adjust metrics to get average values per batch 
    train_loss /= len(dataloader) 
    train_acc /= len(dataloader)
    return train_loss, train_acc



# Create test step function 
def test_step(model: torch.nn.Module, 
              dataloader: torch.utils.data.DataLoader, 
              loss_fn: torch.nn.Module, 
              device: torch.device = device): 
    # Put the model in evaluation mode 
    model.eval()
    
    # Setup loss and accuracy 
    test_loss, test_acc = 0, 0 

    # Turn on inference mode
    with torch.inference_mode(): 

        # Loop through data 
        for batch, (X, y) in enumerate(dataloader): 

            # Send data to device 
            X, y = X.to(device), y.to(device) 

            # 1. Forward Pass 
            y_pred_test = model(X)  # output logits 

            # 2. Calculate loss 
            loss = loss_fn(y_pred_test, y)
            test_loss += loss.item()

            # Calculate accuracy metric 
            y_pred_test_classes = torch.argmax(torch.softmax(y_pred_test, dim=1), dim=1) 
            test_acc += (y_pred_test_classes==y).sum().item()/len(y_pred_test_classes) 

        # Adjust the metrics to get average values per batch 
        test_loss /= len(dataloader) 
        test_acc /= len(dataloader) 
        return test_loss, test_acc
    





from tqdm.auto import tqdm

# Take the various parameters required for training and testing steps 
def train(model: torch.nn.Module,
          train_dataloader: torch.utils.data.DataLoader, 
          test_dataloader: torch.utils.data.DataLoader, 
          optimizer: torch.optim.Optimizer,
          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(), 
          epochs = 5,
          device = device): 
    # 2. Create an empty results dictionary 
    results = {"train_loss": [], 
               "train_acc": [], 
               "test_loss": [],
               "test_acc": []}
    # 3. Loop through the training and testing steps for a few epochs 
    for epoch in tqdm(range(epochs)): 
        train_loss, train_acc = train_step(model=model, 
                                           dataloader=train_dataloader, 
                                           loss_fn=loss_fn, 
                                           optimizer=optimizer, 
                                           device=device)
        test_loss, test_acc = test_step(model=model, 
                                        dataloader=test_dataloader, 
                                        loss_fn=loss_fn, 
                                        device=device)

        # 4. Print out what's happening 
        print(f"Epoch: {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f} |")

        # 5. Update results dictionary 
        results["train_loss"].append(train_loss) 
        results["train_acc"].append(train_acc) 
        results["test_loss"].append(test_loss) 
        results["test_acc"].append(test_acc) 

    # 6. Return the results dict 
    return results 






# Set random seeds 
torch.manual_seed(42) 
torch.cuda.manual_seed(42) 

# Set number of epochs
NUM_EPOCHS = 5

# Recreate an instance of TinyVGG
model_0 = TinyVGG(input_shape=3, # number of color channels - C (3 for RGB) 
                  hidden_units=10, 
                  output_shape=len(train_data.classes)).to(device)

# Setup loss function and optimizer 
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)

# start the timer 
from timeit import default_timer as timer
start_time = timer() 

# Train model_0 
model_0_results = train(model=model_0, 
                        train_dataloader=train_dataloader_simple, 
                        test_dataloader=test_dataloader_simple, 
                        optimizer=optimizer, 
                        loss_fn=loss_fn, 
                        epochs=NUM_EPOCHS, 
                        device=device)

# End the timer and print how long it took  
end_time = timer() 
print(f"\nTotal Training time: {end_time-start_time:.3f} seconds")


model_0_results



