





# Import PyTorch
import torch
from torch import nn

# Import Torchvision
import torchvision
from torchvision import datasets 
from torchvision import transforms
from torchvision.transforms import ToTensor





# Setup training data 
train_data = torchvision.datasets.FashionMNIST(
    root="data", # where to download data?
    train=True, # do we want train data or only test data?
    transform=torchvision.transforms.ToTensor(), # how do we want to transform the data?
    target_transform=None, # how do we want to transform the target?
    download=True 
)

# Setup testing data 
test_data = torchvision.datasets.FashionMNIST(
    root="data", 
    train=False, 
    transform=ToTensor(), 
    target_transform=None
)


len(train_data), len(test_data)


# Check the data
image, label = train_data[0]


image,label


# Check the class names
class_names = train_data.classes
class_names


# Check class index
class_to_idx = train_data.class_to_idx
class_to_idx


train_data.targets


print(f"Image shape: {image.shape}: -> [color_channels, height, width]")
print(f"Image Label : {class_names[label]}")


# Visualizing the data 
import matplotlib.pyplot as plt 

image, label = train_data[0]
plt.imshow(image.squeeze())
plt.title(class_names[label])
plt.axis(False)


plt.imshow(image.squeeze(), cmap='gray')
plt.title(class_names[label])
plt.axis(False)


# Plot some more random images
torch.manual_seed(42)
fig = plt.figure(figsize=(9,9))
rows, cols = 4, 4 
for i in range(1, rows*cols+1): 
    random_idx = torch.randint(0, len(train_data), size=[1]).item()
    img, label = train_data[random_idx]
    fig.add_subplot(rows, cols, i)
    plt.imshow(img.squeeze(), cmap="gray")
    plt.title(class_names[label])
    plt.axis(False)
    





from torch.utils.data import DataLoader

# Setup the batch size hyperparameter
BATCH_SIZE = 32

# Turn datasets into iterables (batches)
train_dataloader = DataLoader(dataset=train_data,
                             batch_size=BATCH_SIZE, 
                             shuffle=True)  # It is necessary to shuffle train data 

test_dataloader = DataLoader(dataset=test_data, 
                            batch_size=BATCH_SIZE, 
                            shuffle=False)  # It is not necessary to shuffle test data 

train_dataloader, test_dataloader


# Let's check out 
print(f"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}")
print(f"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}")


# Check out what's inside dataloader 
train_features_batch, train_labels_batch = next(iter(train_dataloader))
test_features_batch, test_labels_batch =  next(iter(test_dataloader))
train_features_batch.shape, train_labels_batch.shape


# let's visualize a sample 
torch.manual_seed(42)

random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()
img, label = train_features_batch[random_idx], train_labels_batch[random_idx] 
plt.imshow(img.squeeze(), cmap="gray")
plt.title(class_names[label])
plt.axis(False)
print(f"Image Size: {img.shape}")
print(f"Image Label: {class_names[label]}, label_size: {label.shape}")





# Create a flatten layer 
flatten_layer = nn.Flatten() 

# Take a single samle 
x = train_features_batch[0] 

# Forward Pass 
output = flatten_layer(x)

print(f"Input shape: {x.shape} -> [color_channels, height, width]") 
print(f"output shape: {output.shape} -> [color_channels, height*width]")


from torch import nn 

class FashionMNISTV0(nn.Module): 
    def __init__(self, 
                 input_shape: int, 
                 hidden_units: int, 
                 output_shape:int):
        super().__init__()
        self.layer_stack = nn.Sequential(
            nn.Flatten(), 
            nn.Linear(in_features=input_shape, 
                     out_features=hidden_units), 
            nn.Linear(in_features=hidden_units, out_features=output_shape)
        )

    def forward(self, x): 
        return self.layer_stack(x)


torch.manual_seed(42)

model_0 = FashionMNISTV0(
    input_shape=28*28, 
    hidden_units=10, 
    output_shape=len(class_names)
) 

model_0


dummy_x = torch.rand([1, 1, 28, 28])
model_0(dummy_x)


model_0.state_dict()





# helper_functions.py already downloaded
from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params=model_0.parameters(), 
                            lr=0.1)





from timeit import default_timer as timer

def print_train_timer(start: float,
                     end: float, 
                     device=None):
    total_time = end-start
    print(f"\nTotal time {total_time:.3f} seconds trained on {device}")
    return total_time





# import tqdm 
from tqdm.auto import tqdm 

# set manual seed and start timer 
torch.manual_seed(42)
start_time = timer() 

# Create training loop 
epochs = 3 
for epoch in tqdm(range(epochs)): 
    print(f"\nEpoch: {epoch}\n---")
    train_loss = 0

    for batch, (X, y) in enumerate(train_dataloader):
        ### Training  
        model_0.train()
        
        # 1. Forward pass
        y_pred = model_0(X) 

        # 2. Calculate loss per batch
        loss = loss_fn(y_pred, y) 
        train_loss += loss
        # acc = accuracy_fn(y, y_pred) 

        # 3. Optimizer zero grad 
        optimizer.zero_grad() 

        # 4. Loss backward 
        loss.backward() 

        # 5. step optimizer 
        optimizer.step() 

        # print out what's happening 
        if batch % 400 == 0: 
            print(f"Looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples")

    # calculate the train loss average per batch
    train_loss /= len(train_dataloader)

    ### Testing 
    test_loss, test_acc = 0, 0
    model_0.eval()
    with torch.inference_mode(): 
        for X_test, y_test in test_dataloader: 

            # 1. Forward pass 
            test_pred = model_0(X_test) 

            # 2. Calculate loss and accuracy 
            test_loss += loss_fn(test_pred, y_test) 
            test_acc += accuracy_fn(y_test, test_pred.argmax(dim=1))

        # calculate the test looss anc accuracy average per batch 
        test_loss /= len(test_dataloader)
        test_acc /= len(test_dataloader)

    # Print out what's happening 
    print(f"Train Loss: {train_loss:.5f} | Test Loss: {test_loss:.5f} | Test Acc: {test_acc:.2f}")

# Calculating training time 
end_time = timer() 
total_train_time_model_0 = print_train_timer(start=start_time, 
                 end=end_time,
                 device=str(next(model_0.parameters()).device))
total_train_time_model_0
        
    





# create an evaluation funcion 
torch.manual_seed(42)
def eval_model(model: torch.nn.Module, 
              dataloader: torch.utils.data.dataloader, 
              loss_fn: torch.nn.Module,
              accuracy_fn):
    """ Returns a dictinoary containing the results of model predicting on dataloader """
    loss, acc = 0, 0
    model.eval()
    with torch.inference_mode(): 
        for X, y in tqdm(dataloader): 
            # Make predictions 
            y_pred = model(X)

            # Accumulate loss and accuracy 
            loss += loss_fn(y_pred, y)
            acc += accuracy_fn(y, y_pred.argmax(dim=1))

        # scale loss and accuracy 
        loss /= len(dataloader)
        acc /= len(dataloader) 

    return {"model_name": model.__class__.__name__, # only works when the model was created with a class
           "model_loss": loss.item(),
           "model_accuracy": acc}

# calculate the model_0 results 
model_0_results = eval_model(model=model_0, 
                             dataloader=test_dataloader, 
                             loss_fn=loss_fn, 
                             accuracy_fn=accuracy_fn)

model_0_results
            





device = 'cuda' if torch.cuda.is_available() else 'cpu'
device





class FashionMNISV1(nn.Module): 
    def __init__(self, 
                 input_shape: int, 
                 hidden_units: int, 
                 output_shape: int):
        super().__init__() 
        self.layer_stack = nn.Sequential(
            nn.Flatten(), # Flatten the inputs into a single vector 
            nn.Linear(in_features=input_shape, out_features=hidden_units), 
            nn.ReLU(), 
            nn.Linear(in_features=hidden_units, out_features=output_shape), 
            nn.ReLU()
        )

    def forward(self, x): 
        return self.layer_stack(x)


# create an instance of the model and send to device 
torch.manual_seed(42)
model_1 = FashionMNISV1(input_shape=784, hidden_units=10, output_shape=len(class_names)).to(device)





from helper_functions import accuracy_fn
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params=model_1.parameters(), 
                            lr=0.1)





torch.manual_seed(42)

def train_step(model: torch.nn.Module, 
               data_loader: torch.utils.data.dataloader, 
               loss_fn: torch.nn.Module, 
               optimizer: torch.optim.Optimizer, 
               accuracy_fn, 
               device: torch.device = device):
    """ Performs a training with model trying to learn on data_loader """
    train_loss, train_acc = 0, 0 

    # Put model in trainig mode 
    model.to(device)
    model.train()

    # Add a loop to loop throught the training batches
    for batch, (X, y) in enumerate(data_loader):
        # Put data in the target device 
        X, y = X.to(device), y.to(device)

        # 1. Forward pass
        y_pred = model(X) 

        # 2. Calculate loss per batch
        loss = loss_fn(y_pred, y)
        train_loss += loss
        train_acc += accuracy_fn(y, y_pred.argmax(dim=1))

        # 3. Optimizer zero grad 
        optimizer.zero_grad() 

        # 4. Loss backward 
        loss.backward() 

        # 5. step optimizer 
        optimizer.step() 

    # calculate the train loss and train acc average per batch
    train_loss /= len(data_loader)
    train_acc /= len(data_loader)

    print(f"Train Loss: {train_loss:.5f} | Train Acc: {train_acc:.2f}%")


def test_step(model: torch.nn.Module, 
               data_loader: torch.utils.data.dataloader, 
               loss_fn: torch.nn.Module, 
               optimizer: torch.optim.Optimizer, 
               accuracy_fn, 
               device: torch.device = device):
    """ Performs a testing step on model going over data_loader """
    test_loss, test_acc = 0, 0 

    # Put model in trainig mode 
    model.to(device)
    model.eval()

    with torch.inference_mode(): 
        # Add a loop to loop throught the training batches
        for batch, (X, y) in enumerate(data_loader):
            # Put data in the target device 
            X, y = X.to(device), y.to(device)
    
            # 1. Forward pass
            test_pred = model(X) 
    
            # 2. Calculate loss per batch
            test_loss += loss_fn(test_pred, y)
            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))

        # calculate the train loss and train acc average per batch
        test_loss /= len(data_loader)
        test_acc /= len(data_loader)
        
    print(f"Test Loss:  {test_loss:.5f} | Test Acc: {test_acc:.2f}%\n")



torch.manual_seed(42)

# Set timer 
from timeit import default_timer as timer 
start_time_gpu = timer() 

epochs = 3 

# create optimization and evaluation loop using train_step() and test_step() 
for epoch in tqdm(range(epochs)): 
    print(f"Epoch: {epoch}\n----------")
    train_step(model=model_1, 
              data_loader=train_dataloader, 
              loss_fn=loss_fn, 
              optimizer=optimizer, 
              accuracy_fn=accuracy_fn, 
              device=device) 
    test_step(model=model_1, 
             data_loader=test_dataloader, 
             loss_fn=loss_fn, 
             optimizer=optimizer, 
             accuracy_fn=accuracy_fn, 
             device=device)

# set timer and caluclate the time
end_time_gpu = timer() 
total_train_time_model_1 = print_train_timer(start=start_time_gpu, 
                 end=end_time_gpu, 
                 device=device)

total_train_time_model_1

    



torch.manual_seed(42)

# Note: This will error due to `eval_model()` not using device agnostic code 
model_1_results = eval_model(model=model_1, 
    dataloader=test_dataloader,
    loss_fn=loss_fn, 
    accuracy_fn=accuracy_fn) 
model_1_results 





# Move values to device
torch.manual_seed(42)
def eval_model(model: torch.nn.Module, 
               data_loader: torch.utils.data.DataLoader, 
               loss_fn: torch.nn.Module, 
               accuracy_fn, 
               device: torch.device = device):
    """Evaluates a given model on a given dataset.

    Args:
        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.
        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.
        loss_fn (torch.nn.Module): The loss function of model.
        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.
        device (str, optional): Target device to compute on. Defaults to device.

    Returns:
        (dict): Results of model making predictions on data_loader.
    """
    loss, acc = 0, 0
    model.eval()
    with torch.inference_mode():
        for X, y in data_loader:
            # Send data to the target device
            X, y = X.to(device), y.to(device)
            y_pred = model(X)
            loss += loss_fn(y_pred, y)
            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))
        
        # Scale loss and acc
        loss /= len(data_loader)
        acc /= len(data_loader)
    return {"model_name": model.__class__.__name__, # only works when model was created with a class
            "model_loss": loss.item(),
            "model_accuracy": acc}

# Calculate model 1 results with device-agnostic code 
model_1_results = eval_model(model=model_1, data_loader=test_dataloader,
    loss_fn=loss_fn, accuracy_fn=accuracy_fn,
    device=device
)
model_1_results


print(model_0_results) 
total_train_time_model_0











# Create a convolution neural network 
class FashionMNISTModelV2(nn.Module): 
    def __init__(self, input_shape: int, hidden_units: int, output_shape: int): 
        super().__init__() 
        self.conv_block_1 = nn.Sequential(
            nn.Conv2d(in_channels=input_shape, 
                      out_channels=hidden_units, 
                      kernel_size=3, 
                      stride=1, 
                      padding=1),
            nn.ReLU(), 
            nn.Conv2d(in_channels=hidden_units, 
                      out_channels=hidden_units, 
                      kernel_size=3, 
                      stride=1, 
                      padding=1), 
            nn.ReLU(), 
            nn.MaxPool2d(kernel_size=2)
        ) 

        self.conv_block_2 = nn.Sequential(
            nn.Conv2d(in_channels=hidden_units, 
                      out_channels=hidden_units, 
                      kernel_size=3, 
                      stride=1, 
                      padding=1), 
            nn.ReLU(), 
            nn.Conv2d(in_channels=hidden_units, 
                      out_channels=hidden_units, 
                      kernel_size=3, 
                      stride=1, 
                      padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )

        self.classifier = nn.Sequential(
            nn.Flatten(), 
            nn.Linear(in_features=hidden_units*7*7, 
                      out_features=output_shape)
        ) 
        
    def forward(self, x): 
        x = self.conv_block_1(x) 
        x = self.conv_block_2(x)
        x = self.classifier(x) 
        return x
        


# create instance of the model 
torch.manual_seed(42) 
model_2 = FashionMNISTModelV2(input_shape=1, 
                              hidden_units=10, 
                              output_shape=len(class_names)).to(device)





torch.manual_seed(42)

# create a batch of images 
images = torch.randn([32, 3, 64, 64]) 
test_image = images[0] 

print(f"Images barch shape: {images.shape}") 
print(f"Single image shape: {test_image.shape}")
print()
print(f"Test Image: {test_image}")


# create a single convolution layer 
torch.manual_seed(42) 

conv_layer = nn.Conv2d(in_channels=3, 
                       out_channels=10, 
                       kernel_size=3, 
                       stride=1, 
                       padding=1)

# Pass the test image throught the conv layer 
conv_output = conv_layer(test_image)
conv_output.shape





print(f"test_image original shape: {test_image.shape}")

# Create a maxpool2d layer 
maxpool_layer = nn.MaxPool2d(kernel_size=2)

test_image_after_conv = conv_layer(test_image) 
print(f"Shape of after going through conv_layer: {test_image_after_conv.shape}") 

test_image_after_conv_and_maxpool = maxpool_layer(test_image_after_conv)
print(f"Shape of after going through conv_layer and maxpool: {test_image_after_conv_and_maxpool.shape}")





# setup loss function/eval metrics/optimizer 
from helper_functions import accuracy_fn

loss_fn = torch.nn.CrossEntropyLoss() 
optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)





torch.manual_seed(42) 
torch.cuda.manual_seed(42) 

# Measure time
start_time_model_2 = timer() 

# Train and test model 
epochs = 3 

for epoch in tqdm(range(epochs)): 
    print(f"Epoch: {epoch}\n----------")
    
    ### Training 
    train_step(model=model_2, 
               data_loader=train_dataloader, 
               loss_fn=loss_fn, 
               optimizer=optimizer, 
               accuracy_fn=accuracy_fn, 
               device=device) 

    ### Testing 
    test_step(model=model_2, 
              data_loader=test_dataloader, 
              loss_fn=loss_fn, 
              optimizer=optimizer, 
              accuracy_fn=accuracy_fn, 
              device=device) 

end_time_model_2 = timer() 

total_train_time_model_2 = print_train_timer(start=start_time_model_2, 
                                             end=end_time_model_2, 
                                             device=device)
total_train_time_model_2


# Get model_2 results 

model_2_results = eval_model(model=model_2, 
                             data_loader=test_dataloader, 
                             loss_fn=loss_fn,
                             accuracy_fn=accuracy_fn,
                             device=device)
model_2_results





import pandas as pd 

# Create a dataframe containing the model results 
compare_results = pd.DataFrame([model_0_results, 
                               model_1_results, 
                               model_2_results])
compare_results


# Add training time to results comparision 
compare_results['training_time'] = [total_train_time_model_0, total_train_time_model_1, total_train_time_model_2]
compare_results





# Visualize the model results 


compare_results.set_index('model_name')['model_accuracy'].plot(kind='barh')
plt.xlabel("accuracy (%)") 
plt.ylabel('model')





def make_predictions(model: torch.nn.Module, 
                     data: list, 
                     device: torch.device = device): 
    """ Returns tensor containing the predictions got from the model passed """
    pred_probs = []
    model.to(device)
    model.eval() 
    with torch.inference_mode(): 
        for sample in data:
            # Prepare sample
            sample = torch.unsqueeze(sample, dim=0).to(device)
            # Forward Pass
            pred_logit = model(sample) 

            # Get prediction probabilities (logits --> pred probs)
            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)

            # Get pred_prob off GPU for further calculations
            pred_probs.append(pred_prob.cpu())

    # Stack the pred_probs to turn lists into tensor
    return torch.stack(pred_probs)
            
        


# Getting some random samples

import random
# random.seed(42) 

# Create empty lists for sample images and labels 
test_samples = [] 
test_labels = [] 

for sample, label in random.sample(list(test_data), k=9): 
    test_samples.append(sample) 
    test_labels.append(label) 

# View the first sample 
plt.imshow(test_samples[0].squeeze(), cmap='gray') 
plt.title(class_names[test_labels[0]])
plt.axis(False)





# Make prediction  
pred_probs = make_predictions(model=model_2, 
                              data=test_samples, 
                              device=device)

# View first two predictions 
pred_probs[:2]





# Convert prediction probabilities to labels 
pred_classes = pred_probs.argmax(dim=1)
pred_classes


test_labels


# Plot predictions 
plt.figure(figsize=(9,9))
nrows = 3
ncols = 3
for i, sample in enumerate(test_samples): 
    # Create subplot 
    plt.subplot(nrows, ncols, i+1)

    # Plot the target image 
    plt.imshow(sample.squeeze(), cmap="gray") 

    # Find the prediction (in text form e.g 'sandal')
    pred_label = class_names[pred_classes[i]] 

    # Get the truth label 
    truth_label = class_names[test_labels[i]] 

    # Create title for the plot 
    title_text = f"Pred: {pred_label} | Truth: {truth_label}"

    # Check equality for the prediction and truth and change the color of title text 
    if pred_label ==  truth_label: 
        plt.title(title_text, fontsize=10, c="b") 
    else: 
        plt.title(title_text, fontsize=10, c="r")

    plt.axis(False)


        
    





from tqdm.auto import tqdm 

# 1. Make predictions with trained model
y_preds = [] 
model_2.eval() 
with torch.inference_mode(): 
    for X, y in tqdm(test_dataloader, desc="Making predictions"): 
        # Send the data to device
        X, y = X.to(device), y.to(device)
        # Forward pass 
        y_logit = model_2(X)
        # get pred_classes [logits -> probs -> labels]
        y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1) 
        # Put predictions on CPU for evvaluation 
        y_preds.append(y_pred.cpu())

# Concatenate the list of preds into a tensor 
y_preds_tensor = torch.cat(y_preds)
y_preds_tensor[:10]


len(y_preds_tensor)





# See if torchmetrics exists, if not, install it
try:
    import torchmetrics, mlxtend
    print(f"mlxtend version: {mlxtend.__version__}")
    assert int(mlxtend.__version__.split(".")[1]) >= 19, "mlxtend verison should be 0.19.0 or higher"
except:
    get_ipython().getoutput("pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime")
    import torchmetrics, mlxtend
    print(f"mlxtend version: {mlxtend.__version__}")


from torchmetrics import ConfusionMatrix
from mlxtend.plotting import plot_confusion_matrix

# 2. Setup confusion instance and compare predictions to targets 
confmat = ConfusionMatrix(num_classes=len(class_names), task='multiclass')
confmat_tensor = confmat(preds=y_preds_tensor, 
                         target=test_data.targets)

# 3. Plot the confusino matrix 
fig, ax = plot_confusion_matrix(
    conf_mat=confmat_tensor.numpy(), # Matplotlib likes working with numpy'
    class_names=class_names, 
    figsize=(10,7))






from pathlib import Path

# create model directory path 
MODEL_PATH = Path('models') 
MODEL_PATH.mkdir(parents=True, exist_ok=True)

# Create model save 
MODEL_NAME = "03-Computer_Vision_PyTorch.pth"
MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME

# Save the model state dict 
print(f"Saving model to: {MODEL_SAVE_PATH}")
torch.save(obj=model_2.state_dict(), f=MODEL_SAVE_PATH)



